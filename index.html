<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Ting-Wu Rudy Chin (金廷武)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Ting-Wu Rudy Chin (金廷武)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/me.jpg" alt="alt text" width="146px" height="160px" />&nbsp;</td>
<td align="left"><p>Ph.D. Candidate,<br /> <a href="https://www.ece.cmu.edu/">Electrical and Computer Engineering</a>, <br /><a href="https://www.cmu.edu/">Carnegie Mellon University</a><br /><br />
E-mail: tingwuc [AT] cmu [DOT] edu<br /></p>
<p>Affiliation: [<a href="https://enyac.org">EnyAC</a>] [<a href="https://www.andrew.cmu.edu/user/gaurij/Group.html">OPAL</a>]<br /></p>
<p><a href="https://scholar.google.com/citations?user=olo9cqYAAAAJ&amp;hl">Google Scholar</a></p>
</td></tr></table>
<h2>About me</h2>
<p>I am a fourth-year Ph.D. student co-advised by <a href="https://users.ece.cmu.edu/~dianam/">Prof. Diana Marculescu</a> and <a href="https://www.andrew.cmu.edu/user/gaurij/">Prof. Gauri Joshi</a>. My research interests include <i>Model Compression</i>, <i>Neural Architecture Search</i> and <i>Trasnsfer Learning</i> for <i>Deep ConvNets</i>.<br /><br /> </p>
<p>Before joining CMU, I received the B.S. and M.S. degrees in computer science from National Chiao Tung University (<a href="https://www.nctu.edu.tw/en">NCTU</a>), in 2015 and 2017, respectively.</p>
<h2>Industrial Experiences</h2>
<table class="imgtable"><tr><td>
<img src="images/fairlogo.jpg" alt="alt text" width="146px" height="85px" />&nbsp;</td>
<td align="left"><dl>
<dt>Facebook AI Research</dt>
<dd><p>
2020.05 - 2020.08<br />
Research Intern<br />
Mentors: Ari Morcos<br />
Project: On the Transferability of Channel Optimization</p></dd>
</dl>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/frllogo.png" alt="alt text" width="146px" height="140px" />&nbsp;</td>
<td align="left"><dl>
<dt>Facebook Reality Labs</dt>
<dd><p>
2019.05 - 2019.08<br />
Research Intern<br />
Mentors: Pierce Chuang and Vikas Chandra<br />
Project: One Weight Bitwidth to Rule Them All</p></dd>
</dl>
</td></tr></table>
<table class="imgtable"><tr><td>
<img src="images/msrlogo.jpg" alt="alt text" width="146px" height="160px" />&nbsp;</td>
<td align="left"><dl>
<dt>Microsoft Research</dt>
<dd><p>
2018.05 - 2018.08<br />
Research Intern<br />
Mentors: Cha Zhang<br />
Project: Efficient Model Compression with Learned Global Ranking</p></dd>
</dl>
</td></tr></table>
<h3>First-authored Peer-reviewed Publications</h3>
<ul>
<li><p><i>One Weight Bitwidth to Rule Them All</i><br /> <b>Ting-Wu Chin</b>, Pierce Chuang, Vikas Chandra, Diana Marculescu<br /> European Conference on Computer Vision Workshops (<b>ECCV&rsquo;20 Embedded Vision Workshop</b>) (<b>Best Paper Awards</b>)<br /> [<a href="https://arxiv.org/abs/2008.09916">PDF</a>]</p>
</li>
<li><p><i>Towards Efficient Model Compression via Learned Global Ranking</i><br /> <b>Ting-Wu Chin</b>, Ruizhou Ding, Cha Zhang, Diana Marculescu<br /> The IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR&rsquo;20</b>) (<b>Oral, 5% Acceptance Rate</b>)<br /> [<a href="https://arxiv.org/abs/1904.12368v2">PDF</a>][<a href="https://github.com/cmu-enyac/LeGR">Code</a>]</p>
</li>
<li><p><i>AdaScale: Towards Real-time Video Object Detection using Adaptive Scaling</i><br /> <b>Ting-Wu Chin</b>, Ruizhou Ding, Diana Marculescu<br /> Conference on Machine Learning and Systems (<b>MLSys&rsquo;19</b>) (<b>Oral, 17% Acceptance Rate</b>)<br /> [<a href="https://mlsys.org/Conferences/2019/doc/2019/209.pdf">PDF</a>][<a href="https://www.youtube.com/watch?v=5DKD2o41N9Q">Talk</a>]</p>
</li>
<li><p><i>Domain-Specific Approximation for Object Detection</i><br /> <b>Ting-Wu Chin</b>, Chia-Lin Yu, Matthew Halpern, Hasan Genc, Shiao-Li Tsao, Vijay Janapa Reddi<br /> <b>IEEE Micro</b>, SI: Autonomous Computing<br /> [<a href="https://arxiv.org/abs/1810.02010">PDF</a>]</p>
</li>
</ul>
<h3>First-authored Pre-prints and Non-archival Venues</h3>
<ul>
<li><p><i>PareCO: Pareto-aware Channel Optimization for Slimmable Neural Networks</i><br /> <b>Ting-Wu Chin</b>, Ari S. Morcos, Diana Marculescu<br /> Abridged (4 pages) versions were accepted at <b>KDD 2020 Workshops <a href="https://sites.google.com/view/advml">AdvML</a> and <a href="https://dlp-kdd.github.io/">DLP</a></b> &amp; <b>ICML 2020 Workshops <a href="https://sites.google.com/view/deploymonitormlsystems">DMMLSys</a> and <a href="https://realworldml.github.io/">RealML</a></b><br /> [<a href="https://arxiv.org/abs/2007.11752">arXiv</a>] [<a href="https://realworldml.github.io/files/cr/31_PareCO-realml-paper.pdf">Workshop PDF</a>] [<a href="https://github.com/cmu-enyac/PareCO">Code</a>]</p>
</li>
<li><p><i>Improving the Adversarial Robustness of Transfer Learning via Noisy Feature Distillation</i><br /> <b>Ting-Wu Chin</b>, Cha Zhang, Diana Marculescu<br /> An abridged (4 pages) version was accepted at <b>KDD 2020 Workshop <a href="https://sites.google.com/view/advml">AdvML</a></b><br /> [<a href="https://arxiv.org/abs/2002.02998">arXiv</a>] [<a href="https://drive.google.com/open?id=1-e0_INGp_z6ft2pvXHnHlncE16mTTNq8">Workshop PDF</a>] [<a href="https://github.com/cmu-enyac/Renofeation">Code</a>]</p>
</li>
<li><p><i>Layer-compensated Pruning for Resource-constrained Convolutional Neural Networks</i><br /> <b>Ting-Wu Chin</b>, Cha Zhang, Diana Marculescu<br /> An abridged (4 pages) version was accepted at <b>NeurIPS 2018 Workshop <a href="https://sites.google.com/view/nips-2018-on-device-ml">MLPCD 2</a></b> (<b>Oral</b>)<br /> <i>It is later improved and become our CVPR work &ldquo;LeGR&rdquo;</i><br /> [<a href="https://arxiv.org/abs/1810.00518">arXiv</a>][<a href="https://github.com/cmu-enyac/LeGR">Code</a>]</p>
</li>
</ul>
<h3>Co-authored Peer-reviewed Publications</h3>
<ul>
<li><p><i>Regularizing Activation Distribution for Training Binarized Deep Networks</i><br /> Ruizhou Ding, <b>Ting-Wu Chin</b>, Diana Marculescu, Zeye Liu<br />The IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR&rsquo;19</b>)<br /> [<a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Ding_Regularizing_Activation_Distribution_for_Training_Binarized_Deep_Networks_CVPR_2019_paper.pdf">PDF</a>]</p>
</li>
<li><p><i>FLightNNs: Lightweight Quantized Deep Neural Networks for Fast and Accurate Inference</i><br /> Ruizhou Ding, Zeye Liu, <b>Ting-Wu Chin</b>, Diana Marculescu, R. D. (Shawn) Blanton<br />ACM/IEEE Design Automation Conference (<b>DAC&rsquo;19</b>)<br /> [<a href="https://arxiv.org/abs/1904.02835">PDF</a>]</p>
</li>
<li><p><i>Understanding the Impact of Label Granularity on CNN-based Image Classification</i><br /> Zhuo Chen, Ruizhou Ding, <b>Ting-Wu Chin</b>, Diana Marculescu<br /><b>ICDM 2018 Workshop</b> on Data Science and Big Data Analytics (DSDA)<br /> [<a href="https://arxiv.org/abs/1901.07012">PDF</a>]</p>
</li>
<li><p><i>Designing Adaptive Neural Networks for Energy-Constrained Image Classification</i><br /> Dimitrios Stamoulis, <b>Ting-Wu Chin</b>, Anand Krishnan Prakash, Haocheng Fang, Sribhuvan Sajja, Mitchell Bognar, Diana Marculescu<br />Proceedings of the 37th International Conference on Computer-Aided Design (<b>ICCAD&rsquo;18</b>)<br /> [<a href="https://arxiv.org/abs/1901.07012">PDF</a>]</p>
</li>
</ul>
<h3>Honors and Awards</h3>
<ul>
<li><p>Qualcomm Innovation Fellowship 2020 Finalist</p>
</li>
<li><p>David Barakat and LaVerne Owen-Barakat Fellowship, Carnegie Institute of Technology</p>
</li>
<li><p>3rd Place for Siemens FutureMakers Challenge at CMU</p>
</li>
</ul>
<h3>Service</h3>
<p>Reviewer for <i>NeurIPS&rsquo;20</i>, <i>ICML&rsquo;20</i>, <i>IEEE Journal of Selected Topics in Signal Processing</i>, <i>NeurIPS&rsquo;18 Workshop CDNNRIA</i><br />
Sub-reviewer for <i>MLSys&rsquo;20</i></p>
</td>
</tr>
</table>
</body>
</html>
