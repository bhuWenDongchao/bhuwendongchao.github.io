<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Dongchao Wen (温东超)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Dongchao Wen (温东超)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="images/me4.jpg" alt="alt text" width="190px" height="240px" />&nbsp;</td>
<td align="left">
  <p>
    <br /> Principal Researcher <br />
    <a href="http://www.canon-is.com.cn/index.html">Canon Innovative Solution (Beijing) Co., Ltd.</a><br />
    <br /> Professor of Engineering (正高级工程师) <br /> 
    <a href="http://www.casjob.com/index.php?menu=292&id=3568">Chinese Academy of Sciences</a><br />
    
    <br /> XXX正高级工程技术职称评审委员会评审专家<br /> 
    
    <br /> 中国计算机学会 人工智能与模式识别专业委员会（CCF-AI） 企业执行委员<br /> 
    <a href="https://www.ccf.org.cn/Chapters/TC/TC_Listing/TCAIPR/">中国计算机学会 人工智能与模式识别专业委员会</a><br />
  </p>
  
  <p>
    <a href="https://dblp.org/pid/230/2355.html">https://dblp.org</a><br />
    <a href="https://ieeexplore.ieee.org/author/37086571821">https://ieeexplore.org</a><br />
    <a href="https://www.semanticscholar.org/author/Dongchao-Wen/115712451">https://www.semanticscholar.org</a>
  </p>
</td></tr></table>
  
<h2>Education & Qualification</h2>
<p> I received the B.E. degree (<a href="https://shi.buaa.edu.cn/lijingwen/zh_CN/index.htm">Prof. Jingwen Li （李景文）</a>) in electronic information engineering and the M.S. degree (under supervision of <a href="http://www.ee.buaa.edu.cn/info/1223/16649.htm">Prof. Yinqing Zhou （周荫清）</a> and <a href="https://shi.buaa.edu.cn/chenjie/zh_CN/index.htm">Prof. Jie Chen （陈杰）</a>) in signal and information processing from Beihang University, Beijing, China, in 2002 and 2005, respectively. After that, <b>I got a professor's qualification certificate (professor of engineering)</b> of Chinese Academy of Sciences in 2018. </p>

<h2>Research Interest</h2>
  <p> My current research interests encompass two main areas:</p>
  <p> Trustworthy AI: I am dedicated to addressing various aspects of ensuring the robustness, reliability, explainability, security, and privacy of AI systems. By focusing on these critical factors, I strive to develop AI technologies that can be trusted and relied upon.</p>
  <p> Human Analysis: Within this domain, my research explores topics such as face detection, tracking, recognition, and other related areas that involve the analysis of human behavior and characteristics. Through this work, I aim to enhance our understanding of human-related aspects and contribute to the advancement of AI technologies in effectively analyzing and interpreting such information.</p>
  <p> By pursuing research in these areas, my goal is to make significant contributions to the development of AI technologies that are both trustworthy and capable of effectively analyzing and understanding human-related aspects.</p>

<h2>Professional Experience</h2>
<p> Currently, I am working as Principal Researcher at Canon Innovative Solution (Beijing) Co., Ltd. (formerly known as Canon Information Technology (Beijing) Co., Ltd.). I am leading a dynamic and innovative team, focusing on cutting-edge research in the field of deep learning. Our research endeavors encompass various areas including computer vision, efficient neural network design, and trustworthy deep learning. </p>
<p> Additionally, in 2019 and 2020, I served as the Principal Investigator for a collaborative face recognition technology project with Beijing University of Posts and Telecommunications. Our active participation in the NIST FRVT contest showcased our expertise and dedication to advancing the field of face recognition. </p>
  
<h2>Patents</h2>
<p> <b>I have already filed 100+ patents in CN, JP and US.</b> </p>

<h2>News</h2>
<ul>
<li><p><i> On August.30th, 2024, We achieved <b>No.2</b> out of 706 teams in Phase1, <b>No.11</b> out of 184 teams in Phase2, <b>No.13 (Excellence Awards)</b> in the final phase, in Track 1: Deepfake Image Detection of the "Inclusion・The Global Multimedia Deepfake contest." (Team name: AntiFake) </i></p></li>
  <a href="https://www.kaggle.com/competitions/multi-ffdi/overview">Kaggle: Inclusion・The Global Multimedia Deepfake Detection</a>
<li><p><i> On July.5th, 2023, Face Recognition: My team achieved Rank <b>No.5@(Investigation (R=1, T=0)by Developer) (total: 116 entries)</b> in the world in NIST FRVT 1:N contest. (Team name: CompanyName-000, 1st submission)</i></p></li>
<a href="https://pages.nist.gov/frvt/html/frvt11.html">NIST FRVT</a>
<li><p><i> On March.9th, 2023, Face Recognition: My team achieved Rank <b>No.5@wild category (total: 493 entries)</b> in the world in NIST FRVT 1:1 contest. (Team name: CompanyName-001, 2nd submission)</i></p></li>
<a href="https://pages.nist.gov/frvt/html/frvt1N.html">NIST FRVT</a>
</ul>  
  
<h2>Achievements in Canon</h2>
<ul>
<li><p><i> Face Recognition: My team achieved Rank <b>No.2@Visa-Border, No.1@Visa-Kiosk</b> in the world in NIST FRVT 1:N Investigation contest On Nov.5th, 2020. (Team name: cib-000, 1st submission)</i></p></li>
<li><p><i> Face Recognition: My team achieved Rank <b>No.8</b> in the world in NIST FRVT 1:N Identification contest On Nov.5th, 2020. (Team name: cib-000, 1st submission)</i></p></li>
<li><p><i> Face Recognition: My team achieved Rank <b>No.5</b> in the world in NIST FRVT 1:1 contest On Jan.19th, 2021. (Team name: canon-002, 3rd submission)</i></p></li>  
<li><p><i> Face Recognition: My team achieved Rank <b>No.4</b> in the world in NIST FRVT 1:1 contest On Aug.5th, 2020. (Team name: cib-001, 2nd submission)</i></p></li>
<li><p><i> Face Recognition: My team achieved Rank <b>No.25</b> in the world in NIST FRVT 1:1 contest On Dec.12th, 2019.(Team name: cib-000, 1st submission)</i></p></li>
<a href="https://pages.nist.gov/frvt/html/frvt11.html">NIST FRVT</a>
</ul>  

<h2>Publications</h2>
<h3>In 2025</h3>
<ul>    
   <li><p><i>Easy-to-hard Instance-level Feature Fusion for Co-saliency Detection</i><br /> 
     Ding Chuang, Zhidong Han, Gang Dong, Liang Lingyan, <b>Dongchao Wen</b>, Kaihua Zhang.<br />  
     IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>) 2025. <br /> </p></li>

   <li><p><i>Continuously Learning Video-level Object Tokens for Robust UAV tracking</i><br /> 
     Bin Chen, Shenglong Hu, Gang Dong, Liang Lingyan, <b>Dongchao Wen</b>, Kaihua Zhang.<br />  
     IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>) 2025. <br /> </p></li>

   <li><p><i>Spatio-Semantic Prompt guided Adaptive Segment Anything for Remote Sensing Change Detection</i><br /> 
     Shenglong Hu, Zhidong Han, Gang Dong, Liang Lingyan, <b>Dongchao Wen</b>, Kaihua Zhang.<br />  
     IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>) 2025. <br /> </p></li>
  
   <li><p><i>大模型时代的混合专家系统优化综述 </i><br /> 
     史宏志, 赵健, 赵雅倩, 李茹杨, 魏辉, 胡克坤, <b>温东超</b>, 金良.<br />  
     计算机研究与发展 2025. <br /> </p></li>
</ul>
  
<h3>In 2024</h3>
<ul>  
   <li><p><i>Confidence-Aware RGB-D Face Recognition via Virtual Depth Synthesis </i><br /> 
     Zijian Chen, Mei Wang, Weihong Deng, Hongzhi Shi, <b>Dongchao Wen *</b>, Yingjie Zhang, Xingchen Cui, Jian Zhao.<br />  
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2024. <br /> </p></li>
  <li><p><i>Enhancing Generalization of Invisible Facial Privacy Cloak via Gradient Accumulation </i><br /> 
     Xuannan Liu, Yaoyao Zhong, Weihong Deng, Hongzhi Shi, Xingchen Cui, Yunfeng Yin, <b>Dongchao Wen *</b>.<br />  
    IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>) 2024. <br /> </p></li>
</ul>
  
<h3>In 2023</h3>
<ul>  
  <li><p><i>Gradient Attention Balance Network: Mitigating Face Recognition Racial Bias via Gradient Attention </i><a href="https://openaccess.thecvf.com/content/CVPR2023W/TCV/papers/Huang_Gradient_Attention_Balance_Network_Mitigating_Face_Recognition_Racial_Bias_via_CVPRW_2023_paper.pdf">【Paper】</a><br /> 
    Linzhi Huang, Mei Wang, Jiahao Liang, Weihong Deng, Hongzhi Shi, <b>Dongchao Wen *</b>, Yingjie Zhang, Jian Zhao.<br />  
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2023. (<b>Oral</b>) <br /> </p></li>
  
  <li><p><i>Dive into the Resolution Augmentations and Metrics in Low Resolution Face Recognition: A Plain yet Effective New Baseline</i><a href="https://r2hcai.github.io/AAAI-23/files/CameraReadys/14.pdf">【Paper】</a><br /> 
  Xu Ling, Yichen Lu, Wenqi Xu, Weihong Deng, Yingjie Zhang, Xingchen Cui, Hongzhi Shi, <b>Dongchao Wen *</b>.<br /> 
  R2HCAI: The AAAI 2023 Workshop on Representation Learning for Responsible Human-Centric AI at AAAI Conference on Artificial Intelligence 2023 (<b>AAAI</b>) 2023. <br /> </p></li>

  <li><p><i>Model and Data Agreement for Learning with Noisy Labels</i><a href="https://practical-dl.github.io/2023/long_paper/6/CameraReady/6.pdf">【Paper】</a><br /> 
  Yuhang Zhang, Weihong Deng, Xingchen Cui, Yunfeng Yin, Hongzhi Shi, <b>Dongchao Wen *</b>.<br /> 
  2nd International Workshop on Practical Deep Learning in the Wild Workshop at AAAI Conference on Artificial Intelligence 2023 (<b>AAAI</b>) 2023. <br /> </p></li>
</ul>
  
<h3>In 2022</h3>
<ul> 
  <li><p><i>Face Clustering via Adaptive Aggregation of Clean Neighbors.</i><a href="https://dl.acm.org/doi/10.1145/3552458.3556448">【Paper】</a><br /> 
  Shiyong Hong, Yaobin Zhang, Xu Ling, Weihong Deng, Yin Yunfeng, Zhang Yingjie, Hongzhi Shi, <b>Dongchao Wen *</b>.<br /> 
  The 3rd International Workshop on Human-Centric Multimedia Analysis (HCMA '22) in conjunction with ACM International Conference on Multimedia (<b>MM</b>) 2022. <br /> </p></li>
  
  <li><p><i>Improving Autism Spectrum Disorder Prediction by Fusion of Multiple Measures of Resting-State Functional MRI Data.</i><a href="https://ieeexplore.ieee.org/document/9871167">【Paper】</a><br /> 
  Lingyan Liang, Gang Dong, Changsheng Li, <b>Dongchao Wen </b>, Yaqian Zhao, Jing Li. <br /> 
  44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (<b>EMBC</b>)2022. (<b>Oral</b>) <br /></p></li>
  
  <li><p><i>Dynamic Training Data Dropout for Robust Deep Face Recognition.</i><a href="https://ieeexplore.ieee.org/document/9591391">【Paper】</a><br /> 
  Yaoyao Zhong, Weihong Deng,Han Fang, Jiani Hu, Dongyue Zhao, Xian Li, <b>Dongchao Wen </b>. <br /> 
  IEEE Transactions on Multimedia (<b>TMM</b>) 2022. <br /> </p></li>
</ul>
  
<h3>In 2021</h3>
<ul>
  <li><p><i>FTAFace: Context-enhanced Face Detector with Fine-grained Task Attention.</i><a href="https://dl.acm.org/doi/10.1145/3474085.3475500">【Paper】</a><br /> 
  Deyu Wang, <b>Dongchao Wen *</b>, Wei Tao, Lingxiao Yin, Tse-Wei Chen, Tadayuki Ito, Kinya Osa, Masami Kato.<br /> 
  ACM International Conference on Multimedia (<b>MM</b>) 2021. <br /> </p></li>

 <li><p><i>CASSOD-Net: Cascaded and Separable Structures of Dilated Convolutional Neural Networks for Embedded Vision Systems and Applications.</i><a href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/papers/Chen_CASSOD-Net_Cascaded_and_Separable_Structures_of_Dilated_Convolution_for_Embedded_CVPRW_2021_paper.pdf">【Paper】</a><br /> 
  Tse-Wei Chen, Deyu Wang, Wei Tao,<b>Dongchao Wen</b>, Lingxiao Yin, Tadayuki Ito, Kinya Osa, Masami Kato. <br /> 
  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2021. (<b>Oral</b>)<br /> </p></li>
  
 <li><p><i>Augmented Face Representation Learning via Transitive Distillation.</i><a href="https://dl.acm.org/doi/10.1109/FG52635.2021.9666949">【Paper】</a><br /> 
  Han Fang, Weihong Deng, Yaoyao Zhong, Jiani Hu, Dongyue Zhao, Xian Li, <b>Dongchao Wen </b>. <br /> 
  IEEE International Conference on Automatic Face and Gesture Recognition 2021 (<b>FG</b>) 2021. <br /> </p></li>
  
<li><p><i>Adaptive Label Noise Cleaning with Meta-Supervision for Deep Face Recognition.</i><a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Adaptive_Label_Noise_Cleaning_With_Meta-Supervision_for_Deep_Face_Recognition_ICCV_2021_paper.html">【Paper】</a><br /> 
  Yaobing Zhang, Weihong Deng, Yaoyao Zhong, Jiani Hu, Xian Li, Dongyue Zhao, <b>Dongchao Wen </b>. <br /> 
  International Conference on Computer Vision (<b>ICCV</b>) 2021. <br /> </p></li>

<li>
  <p><i>Sigmoid-constrained Hyper-sphere Loss for Robust Face Recognition. </i><a href="https://ieeexplore.ieee.org/document/9318547">【Paper】</a><br /> 
    Yaoyao Zhong, Weihong Deng, Jiani Hu, Dongyue Zhao, Xian Li, <b>Dongchao Wen </b>.<br /> 
    IEEE Transactions on Image Processing(<b>TIP</b>), 2021.<br /> 
    开源：基于 SFace 损失函数训练的轻量人脸识别模型贡献了 OpenCV开源库（全球最受欢迎的计算机视觉开源软件，Github 五万多星）的人脸识别模块<a href="https://mp.weixin.qq.com/s/5ccMQtL7BdNgKnMt9f9tTQ">（附实例程序）</a><br /> 
  </p> 
</li>
  
</ul>
  
<h3>In 2020</h3>
<ul>
<li><p><i>Fully Supervised and Guided Distillation for One-Stage Detectors.</i><a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Wang_Fully_Supervised_and_Guided_Distillation_for_One-Stage_Detectors_ACCV_2020_paper.pdf">【Paper】</a><br /> 
  Deyu Wang, <b>Dongchao Wen *</b>, Junjie Liu, Wei Tao, Tse-Wei Chen, Kinya Osa, Masami Kato.<br />
  Asian Conference on Computer Vision  (<b>ACCV</b>) 2020. <br /> </p>
</li>  

<li><p><i>QuantNet: Learning to Quantize by Learning within Fully Differentiable Framework.</i><a href="https://arxiv.org/abs/2009.04626">【Paper】</a><br /> 
  Junjie Liu, <b>Dongchao Wen *</b>, Deyu Wang, Wei Tao, Tse-Wei Chen, Kinya Osa, Masami Kato.<br /> 
  European Conference on Computer Vision Workshops  (<b>ECCVW</b>) 2020. (<b>Oral</b>)<br /> </p>
</li>
  
<li><p><i>Hardware Architecture of Embedded Inference Accelerator and Analysis of Algorithms for Depthwise and Large-Kernel Convolutions.</i><a href="https://arxiv.org/abs/2104.14125">【Paper】</a><br /> 
  Tse-Wei Chen, Wei Tao, Deyu Wang, <b>Dongchao Wen</b>, Masami Kato, Kinya Osa.<br />
  European Conference on Computer Vision Workshops  (<b>ECCVW</b>) 2020. (<b>Oral</b>) <br /> </p>
</li>
  
<li>
  <p><i>BAMSProd: A Step towards Generalizing the Adaptive Optimization Methods to Deep Binary Model.</i><a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Liu_BAMSProd_A_Step_Towards_Generalizing_the_Adaptive_Optimization_Methods_to_CVPRW_2020_paper.pdf">【Paper】</a><br /> 
    Junjie Liu, <b>Dongchao Wen</b>, Deyu Wang, Wei Tao, Tse-Wei Chen, Kinya Osa, Masami Kato. <br /> 
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2020.  (<b>Oral</b>)<br /> </p>
</li>
  
<li><p><i>Global-Local GCN: Large-Scale Label Noise Cleansing for Face Recognition.</i><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Global-Local_GCN_Large-Scale_Label_Noise_Cleansing_for_Face_Recognition_CVPR_2020_paper.pdf">【Paper】</a><br /> 
    Yaobing Zhang, Weihong Deng, Mei Wang, Jiani Hu, Xian Li, Dongyue Zhao, <b>Dongchao Wen </b>.<br /> 
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2020.<br /> </p>
</li>
  
</ul>
<h3>In 2019</h3>
<ul>  
<li><p><i>Condensation-Net: Memory-Efficient Network Architecture With Cross-Channel Pooling Layers and Virtual Feature Maps.</i><a href="https://openaccess.thecvf.com/content_CVPRW_2019/html/EVW/Chen_Condensation-Net_Memory-Efficient_Network_Architecture_With_Cross-Channel_Pooling_Layers_and_Virtual_CVPRW_2019_paper.html">【Paper】</a><br /> 
  Tse-Wei Chen, Motoki Yoshinaga, Hongxing Gao, Wei Tao, <b>Dongchao Wen</b>, Junjie Liu, Kinya Osa, Masami Kato. <br /> 
  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2019.<br /> </p>
</li>

<li><p><i>DupNet: Towards Very Tiny Quantized CNN With Improved Accuracy for Face Detection.</i><a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/EVW/Gao_DupNet_Towards_Very_Tiny_Quantized_CNN_With_Improved_Accuracy_for_CVPRW_2019_paper.pdf">【Paper】</a><br /> 
  Hongxing Gao, Wei Tao, <b>Dongchao Wen</b>, Junjie Liu, Tse-Wei Chen, Kinya Osa, Masami Kato. <br /> 
  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2019.<br /> </p>
</li>

<li>
  <p><i>Knowledge Representing: Efficient, Sparse Representation of Prior Knowledge for Knowledge Distillation.</i><a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Liu_Knowledge_Representing_Efficient_Sparse_Representation_of_Prior_Knowledge_for_Knowledge_CVPRW_2019_paper.pdf">【Paper】</a><br /> 
    Junjie Liu, <b>Dongchao Wen</b>, Hongxing Gao, Wei Tao, Tse-Wei Chen, Kinya Osa, Masami Kato. <br /> 
    IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2019.<br /> </p>
</li>
</ul>
<h3>In 2018</h3>
<ul>   
<li><p><i>IFQ-Net: Integrated Fixed-Point Quantization Networks for Embedded Vision.</i><a href="https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w12/Gao_IFQ-Net_Integrated_Fixed-Point_CVPR_2018_paper.pdf">【Paper】</a><br /> 
  Hongxing Gao, Wei Tao, <b>Dongchao Wen</b>, Tse-Wei Chen, Kinya Osa, Masami Kato. <br /> 
  IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>) 2018. (<b>Oral</b>)<br /> </p></li>
</ul>

<h2>Patents</h2>
<h3>Granted US Patents</h3>
<ul>
<li><p><i>US12165398B2, "Method and apparatus for training an object recognition model"，Dongyue Zhao，<b>Dongchao Wen</b>，Xian Li, Weihong Deng, Jiani Hu.</i></p></li>
<li><p><i>US12147901B2，"Training and application method of a multi-layer neural network model, apparatus and storage medium"，Hongxing Gao，Tao Wei，Tse-Wei Chen，<b>Dongchao Wen</b>，Junjie Liu.</i></p></li>
<li><p><i>US12026974B2, "Training method and training apparatus for a neural network for object recognition"，Dongyue Zhao，<b>Dongchao Wen</b>，Xian Li, Weihong Deng, Jiani Hu.</i></p></li>
<li><p><i>US11847569B2, "Training and application method of a multi-layer neural network model, apparatus and storage medium"，Wei Tao，Hongxing Gao，Tse-Wei Chen，<b>Dongchao Wen</b>，JunjieLiu.</i></p></li>
<li><p><i>US11755880B2, "Method and apparatus for optimizing and applying multilayer neural network model, and storage medium"，Hongxing Gao，Tao Wei，Tse-Wei Chen，<b>Dongchao Wen</b>.</i></p></li>
<li><p><i>US11270108B2, "Object tracking method and apparatus", Shiting Wang, Qi Hu, <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>US11106945B2, "Training and application method of neural network model, apparatus, system and storage medium", Junjie Liu, Tse-Wei Chen, <b>Dongchao Wen</b>, Hongxing Gao, Wei Tao.</i></p></li>
<li><p><i>US10475204B2, "Fast multi-object detection and tracking system", Shiting Wang, Qi Hu, <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>US10318797B2, "Image processing apparatus and image processing method", Donghui Sun, Xian Li, <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>US9600884B2, "Object shape aligning apparatus, object processing apparatus and methods thereof", Fuguo Zhu, Yong Jiang, Xian Li, Lifeng Xu, <b>Dongchao Wen</b>.</i></p></li>  
</ul>

<h3>Granted Japanese Patents</h3>
<ul>
<li><p><i>JP7584998B2, "授权物体認識モデルを学習するための方法および装置", Dongyue Zhao，<b>Dongchao Wen</b>，Xian Li, Weihong Deng, Jiani Hu.</i></p></li>
<li><p><i>JP7371154B2, "顔の姿勢を検出する装置及び方法、画像処理システム、並びに記憶媒体", Qiao Wang, Deyu Wang, Kataro Kitajima, Tse-Wei Chen, Wei Tao, <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>JP7009020B2, "ニューラルネットワークモデルの学習及び適用方法、装置、システム及び記憶媒体", Junjie Liu, Tse-Wei Chen, <b>Dongchao Wen</b>, Wei Tao, Deyu Wang. </i></p></li>
<li><p><i>JP6890653B2, "多層ニューラルネットワークモデルの学習及び適用方法、装置、並びに記憶媒体", Hongxing Gao，Wei Tao, Tse-Wei Chen, <b>Dongchao Wen</b>, Junjie Liu.</i></p></li>
<li><p><i>JP6990813B2, "多層ニューラルネットワークモデルの学習及び適用方法、装置、並びに記憶媒体", Hongxing Gao，Wei Tao, Tse-Wei Chen, <b>Dongchao Wen</b>, Junjie Liu.</i></p></li>
<li><p><i>JP6759411B2，"物体追跡方法および装置"，Shiting Wang, Qi Hu, <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>JP6794593B2, "多階層ニューラルネットワークモデルを最適化して適用する方法及び装置、及び記憶媒体", Hongxing Gao，Wei Tao, Tse-Wei Chen,  <b>Dongchao Wen</b>.</i></p></li>
<li><p><i>JP4966384B2, "シェーディング補正を行なう装置及び方法", <b>Dongchao Wen</b>, Lifeng Xu.</i></p></li>  
<li><p><i>JP4847592B2, "歪み文書画像を補正する方法及びシステム", <b>Dongchao Wen</b>, Lifeng Xu.</i></p></li>  
</ul>
  
<h2>Activities</h2>
<ul>
<dt><li>The Embedded Vision Workshop (in conjunction with CVPR Since 2005)</li></dt>
<table class="imgtable"><tr><td>
<img src="images/evw.jpg" alt="alt text" width="60px" height="75px" />&nbsp;</td>
<td align="left">
  <p>
    Program Committee member<br />
    since 2018<br />
  </p>
  
  <p>
    <a href="https://embeddedvisionworkshop.wordpress.com/">The Embedded Vision Workshop</a>
  </p>
</td></tr></table>
</ul>
 
<h2>Professional Services</h2>
<ul>
<h3> Reviewer for Transactions/Journals </h3>
<li><p><i> <a href="https://mc.manuscriptcentral.com/taffc-cs">Transactions on Affective Computing</a> (<b>TAC</b>)<!-- since 2023--></i></p></li>

<h3> Program Committee/Reviewer for Conferences </h3>
<li><p><i><a href="https://icml.cc/">International Conference on Machine Learning</a> (<b>ICML</b>)<!--: 2024--></i></p></li>
<li><p><i><a href="https://nips.cc/">Annual Conference on Neural Information Processing Systems</a> (<b>NeurIPS</b>)<!--: 2023--></i></p></li>
<li><p><i><a href="https://iclr.cc/">International Conference on Learning Representations</a> (<b>ICLR</b>)<!--: 2024--></i></p></li>  
<li><p><i><a href="https://aaai.org/aaai-conference/">Annual AAAI Conference on Artificial Intelligence</a> (<b>AAAI</b>)<!--: 2025--></i></p></li>    
<li><p><i><a href="https://cvpr.thecvf.com/">IEEE/CVF Conference on Computer Vision and Pattern Recognition</a> (<b>CVPR</b>)<!--: 2024--></i></p></li> 
<li><p><i>IEEE International Conference on Multimedia and Expo (<b>ICME</b>)<!--: 2022,2023,2024--></i></p></li>
<li><p><i>IEEE International Conference on Acoustics, Speech and Signal Processing (<b>ICASSP</b>)<!--: 2023,2024--></i></p></li>
<li><p><i>IEEE International Joint Conference on Neural Networks (<b>IJCNN</b>)<!--: 2023,2024--></i></p></li>  
<li><p><i><a href="https://embeddedvisionworkshop.wordpress.com/">The Embedded Vision Workshop</a> (<b>EVW</b>)<!--: 2018,2019,2020,2021,2022,2023,2024--></i></p></li>
</ul>

<h2> Projects </h2>
<ul>
<li><p><i>---</i></p></li>
</ul> 
  
<h2>Honors and Awards</h2>
<ul>
<!--: <h3>IEIT SYSTEMS Co., Ltd.</h3>
<li><p>Outstanding Staff of the Year 2023 (Crystal Award), IEIT SYSTEMS Co., Ltd., January 2024</p></li>
<li><p>Outstanding Paper Award for 2022 (Top-3), IEIT SYSTEMS Co., Ltd., April 2023</p></li>
<li><p>Outstanding Staf of the Year 2022 (Crystal Award), IEIT SYSTEMS Co., Ltd., January 2023</p></li>
<li><p>Best New Employee Award of the Year 2021, IEIT SYSTEMS Co., Ltd., April 2022</p></li>-->
  
<h3> Canon Innovative Solution (Beijing) Co., Ltd. </h3>
<li><p> 科技创新英才, 中关村科学城总工会, 2021 年 4 月 </p></li>
<li><p> Outstanding Technical Achievement Award, Canon Information Technology (Beijing) Co., Ltd., January 2021. <!--:2020年度优秀技术成果奖, 佳能信息技术(北京)有限公司, 2021 年 1 月--> </p></li>
<li><p> Outstanding Patent Proposal Award, Canon Inc., July 2020. <!--:2019年度优秀专利提案奖, 佳能集团, 2020 年 7 月--> </p> </li>
<li><p> Outstanding Technical Achievement Award, Canon Information Technology (Beijing) Co., Ltd., January 2020. <!--:2019年度优秀技术成果奖, 佳能信息技术(北京)有限公司, 2020 年 1 月--> </p></li>
<li><p> A-level Patent Award, Canon Information Technology (Beijing) Co., Ltd., January 2019. <!--:2018年A 级专利奖, 佳能信息技术(北京)有限公司, 2019 年 1 月--></p></li>
<li><p> Excellent Patent Team Award, Canon Information Technology (Beijing) Co., Ltd., January 2019. <!--:2018年优秀专利团队奖, 佳能信息技术(北京)有限公司, 2019 年 1 月--></p></li>
<li><p> Excellent Patent Team Award, Canon Information Technology (Beijing) Co., Ltd., January 2018. <!--:2017年优秀专利团队奖, 佳能信息技术(北京)有限公司, 2018 年 1 月--></p></li>
<li><p> Excellent Patent Team Award, Canon Information Technology (Beijing) Co., Ltd., January 2016. <!--:2015年优秀专利团队奖, 佳能信息技术(北京)有限公司, 2016 年 1 月--></p></li>  
<li><p> Outstanding Employee in 2007, Canon Information Technology (Beijing) Co., Ltd., January 2008. <!--:2007年优秀员工, 佳能信息技术(北京)有限公司, 2008 年 1 月--></p></li>
<li><p> A-level Patent Award, Canon Information Technology (Beijing) Co., Ltd., January 2008. <!--:2007年A 级专利奖, 佳能信息技术(北京)有限公司, 2008 年 1 月--></p></li>
</ul>

<ul>
<h3> Undergraduate/Graduate Phase </h3>
<li><p> The "611" Scholarship, Beihang University, 2004. <!--:611奖学金, 颁发机构 北京航空航天大学,获奖日期 2004 年-->  </p> </li>
<li><p> The Guanghua Scholarship, Beihang University, 2003. <!--:光华奖学金, 颁发机构 北京航空航天大学,获奖日期 2003 年--> </p></li>
<li><p> The People's Scholarship, by Beihang University, 1999. <!--:人民奖学金, 颁发机构 北京航空航天大学,获奖日期 1999 年--> </p></li>
</ul>
  
<ul>
<h3> High School Phase</h3>
<li><p> Provincial-Level Merit Student, Nei Mongol, 1997. <!--:内蒙古自治区三好学生, 获奖日期 1997 年--> </p></li>
<li><p> Provincial-Level Merit Student, Nei Mongol, 1996. <!--:内蒙古自治区三好学生, 获奖日期 1996 年--> </p></li>
</ul>

<h2> Other Services </h2>  
<ul>
<li><p><i>---</i></p></li>
<!--: <li><p> 佳能信息技术(北京)有限公司 员工代表委员会主任/工会主席 2008年--2020年 </p></li>
<li><p> 佳能信息技术(北京)有限公司 党支部书记 2007年--2019年 </p></li>
<li><p> 北京航空航天大学 电子信息工程学院 研究生会主席, 2003年--2004年 </p></li>-->
</ul>  
<h2> Welcome Visitors </h2>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=5ktie83v0ah&amp;s=350&amp;m=7&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
</td>
</tr>
</table>
</body>
</html>
